# MURF 论文复现报告
本次复现直接使用预训练模型
<p align="center">
  <b>MURF: Mutually Reinforcing Multi-Modal Image Registration and Fusion</b><br>
  <i>多模态图像配准与融合的互增强统一框架</i>
</p>

<p align="center">
  <b>复现报告</b><br>
  复现时间: 2025年12月<br>
  复现环境: Ubuntu 22.04 + TensorFlow 2.10 + NVIDIA RTX 4090 D
</p>

---

## 📋 目录

1. [项目概述](#1-项目概述)
2. [论文核心思想](#2-论文核心思想)
3. [模型原理](#3-模型原理)
4. [实验设置](#4-实验设置)
5. [复现结果](#5-复现结果)
6. [创新点与优势](#6-创新点与优势)
7. [应用场景](#7-应用场景)
8. [总结与展望](#8-总结与展望)
9. [参考文献](#9-参考文献)

---

## 1. 项目概述

### 1.1 论文信息

| 项目         | 内容                                                                   |
| ------------ | ---------------------------------------------------------------------- |
| **论文标题** | MURF: Mutually Reinforcing Multi-Modal Image Registration and Fusion   |
| **中文标题** | MURF: 多模态图像配准与融合的互增强统一框架                             |
| **发表期刊** | IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) |
| **发表年份** | 2023                                                                   |
| **作者**     | Han Xu, Jiayi Ma, Jiteng Yuan, Zhuliang Le, Wei Liu                    |
| **机构**     | 武汉大学电子信息学院                                                   |
| **影响因子** | 23.6 (2023)                                                            |

### 1.2 研究背景

多模态图像融合 (Multi-Modal Image Fusion) 是计算机视觉领域的重要研究方向，旨在将不同传感器获取的互补信息整合到一张图像中。典型的应用场景包括：

- **可见光-红外融合**: 结合可见光的纹理细节和红外的热辐射信息
- **医学图像融合**: 如 PET-MRI、CT-MRI 融合，综合功能和解剖信息

然而，现有方法面临两个主要挑战：

1. **配准与融合的割裂**: 传统方法将配准和融合作为两个独立任务，忽略了它们之间的相互依赖关系
2. **跨模态差异**: 不同模态图像具有显著的外观差异，难以直接进行特征匹配

### 1.3 复现目标

本项目旨在完整复现 MURF 论文中的四个模态融合任务：

| 模态    | 描述                            | 应用领域           |
| ------- | ------------------------------- | ------------------ |
| RGB-IR  | 可见光-红外融合                 | 安防监控、自动驾驶 |
| RGB-NIR | 可见光-近红外融合               | 遥感、农业监测     |
| PET-MRI | 正电子发射断层扫描-核磁共振融合 | 肿瘤诊断           |
| CT-MRI  | 计算机断层扫描-核磁共振融合     | 临床诊断           |

---

## 2. 论文核心思想

### 2.1 互增强机制

MURF 的核心创新在于提出了**配准与融合的互增强 (Mutually Reinforcing)** 机制：

```
配准 (Registration) ←→ 融合 (Fusion)
       ↑                    ↑
       └──── 相互促进 ────────┘
```

- **融合辅助配准**: 融合后的图像可以提供更丰富的跨模态对应信息，指导配准网络学习更准确的变换
- **配准辅助融合**: 准确的配准可以消除几何失配，使融合网络专注于信息整合

### 2.2 统一框架设计

MURF 将多模态图像融合分解为三个级联任务：

```
┌─────────────────────────────────────────────────────────────────┐
│                         MURF 框架                                │
├─────────────────────────────────────────────────────────────────┤
│  ┌───────────────────┐   ┌───────────────────┐   ┌───────────┐ │
│  │ Task 1:           │   │ Task 2:           │   │ Task 3:   │ │
│  │ 共享信息提取      │ → │ 多尺度粗配准      │ → │ 精细配准  │ │
│  │                   │   │                   │   │ 与融合    │ │
│  └───────────────────┘   └───────────────────┘   └───────────┘ │
│         ↓                        ↓                     ↓        │
│    跨模态描述符              粗略对齐图像          融合结果      │
└─────────────────────────────────────────────────────────────────┘
```

---

## 3. 模型原理

### 3.1 Task 1: 共享信息提取网络

**目标**: 从不同模态图像中提取共享的结构描述符，弥合模态间隙

**网络结构**:

```
输入图像 (H×W×C)
    ↓
┌─────────────────┐
│  编码器网络     │  (多层卷积 + 下采样)
│  Encoder        │
└────────┬────────┘
         ↓
┌─────────────────┐
│  描述符提取器   │  (特征聚合 + 归一化)
│  Descriptor     │
└────────┬────────┘
         ↓
共享描述符 (H×W×D)
```

**关键设计**:
- 使用对比学习约束，确保同一场景不同模态的描述符相似
- 描述符仅保留模态间共享的结构信息，过滤掉模态特有的外观差异

**损失函数**:

$$\mathcal{L}_{desc} = \mathcal{L}_{ssim} + \lambda_1 \mathcal{L}_{grad} + \lambda_2 \mathcal{L}_{content}$$

其中：
- $\mathcal{L}_{ssim}$: 结构相似性损失
- $\mathcal{L}_{grad}$: 梯度损失
- $\mathcal{L}_{content}$: 内容一致性损失

### 3.2 Task 2: 多尺度粗配准网络

**目标**: 估计源图像到目标图像的仿射变换参数

**网络结构**:

```
┌─────────────────────────────────────────────────────────────┐
│                    多尺度金字塔                              │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Level 1 (1/4)     Level 2 (1/2)     Level 3 (1/1)         │
│  ┌─────────┐       ┌─────────┐       ┌─────────┐           │
│  │ 特征提取 │ ───→ │ 特征提取 │ ───→ │ 特征提取 │           │
│  └────┬────┘       └────┬────┘       └────┬────┘           │
│       ↓                 ↓                 ↓                 │
│  ┌─────────┐       ┌─────────┐       ┌─────────┐           │
│  │ 仿射估计 │ ───→ │ 仿射估计 │ ───→ │ 仿射估计 │           │
│  └────┬────┘       └────┬────┘       └────┬────┘           │
│       ↓                 ↓                 ↓                 │
│     θ_1    ──────→    θ_2    ──────→    θ_3                │
│   (粗略)              (中等)             (精细)              │
│                                                             │
└─────────────────────────────────────────────────────────────┘
                              ↓
                        最终仿射矩阵 θ
```

**仿射变换**:

$$\begin{bmatrix} x' \\ y' \\ 1 \end{bmatrix} = \begin{bmatrix} a_{11} & a_{12} & t_x \\ a_{21} & a_{22} & t_y \\ 0 & 0 & 1 \end{bmatrix} \begin{bmatrix} x \\ y \\ 1 \end{bmatrix}$$

**损失函数**:

$$\mathcal{L}_{reg} = \mathcal{L}_{photo} + \lambda_3 \mathcal{L}_{desc} + \lambda_4 \mathcal{L}_{smooth}$$

### 3.3 Task 3: 精细配准与融合网络

**目标**: 在粗配准基础上进行像素级精细对齐，并融合多模态信息

**网络结构**:

```
┌─────────────────────────────────────────────────────────────┐
│                    精细配准与融合网络                         │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  粗配准图像A          粗配准图像B                            │
│       ↓                    ↓                                │
│  ┌─────────┐          ┌─────────┐                          │
│  │ 编码器A │          │ 编码器B │                          │
│  └────┬────┘          └────┬────┘                          │
│       ↓                    ↓                                │
│       └────────┬──────────┘                                 │
│                ↓                                            │
│  ┌─────────────────────────────────┐                       │
│  │      可变形卷积 (Deformable)     │  ← 学习像素级偏移     │
│  │      + 通道注意力 (Channel Attn) │  ← 自适应特征加权     │
│  └─────────────┬───────────────────┘                       │
│                ↓                                            │
│  ┌─────────────────────────────────┐                       │
│  │         融合解码器               │                       │
│  └─────────────┬───────────────────┘                       │
│                ↓                                            │
│           融合结果                                           │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**可变形卷积**:

通过学习偏移量 $\Delta p$ 实现自适应的感受野：

$$y(p_0) = \sum_{p_n \in \mathcal{R}} w(p_n) \cdot x(p_0 + p_n + \Delta p_n)$$

**融合损失函数**:

$$\mathcal{L}_{fuse} = \mathcal{L}_{ssim} + \lambda_5 \mathcal{L}_{grad} + \lambda_6 \mathcal{L}_{int}$$

---

## 4. 实验设置

### 4.1 复现环境

| 配置项     | 规格                                 |
| ---------- | ------------------------------------ |
| 操作系统   | Ubuntu 22.04 LTS                     |
| CPU        | Intel Xeon (多核)                    |
| GPU        | NVIDIA RTX 4090 D × 8 (24GB 显存/卡) |
| CUDA       | 11.x (pip nvidia-cudnn-cu11)         |
| cuDNN      | 8.6.0.163                            |
| Python     | 3.8.20                               |
| TensorFlow | 2.10.0                               |
| 内存       | 256GB                                |

### 4.2 数据集

| 模态    | 数据集          | 来源         | 测试图像数 |
| ------- | --------------- | ------------ | ---------- |
| RGB-IR  | RoadScene       | 自建         | 4          |
| RGB-NIR | VIS-NIR Scene   | Brown et al. | 1          |
| PET-MRI | Harvard Medical | Harvard      | 1          |
| CT-MRI  | Harvard Medical | Harvard      | 1          |

### 4.3 预训练模型

| 模态    | Task 1    | Task 2    | Task 3    |
| ------- | --------- | --------- | --------- |
| RGB-IR  | 4200.ckpt | 6400.ckpt | 0000.ckpt |
| RGB-NIR | 3600.ckpt | 9300.ckpt | ❌ 无      |
| PET-MRI | 0000.ckpt | 0000.ckpt | 0000.ckpt |
| CT-MRI  | 0000.ckpt | 0000.ckpt | 0000.ckpt |

---

## 5. 复现结果

### 5.1 任务完成情况

| 模块        | Task 1 | Task 2 | Task 3 | 完成度 |
| ----------- | :----: | :----: | :----: | :----: |
| **RGB-IR**  |   ✅    |   ✅    |   ✅    |  100%  |
| **RGB-NIR** |   ✅    |   ✅    |   ❌    |  67%   |
| **PET-MRI** |   ✅    |   ✅    |   ✅    |  100%  |
| **CT-MRI**  |   ✅    |   ✅    |   ✅    |  100%  |

**总体完成度**: 11/12 任务 (91.7%)

### 5.2 定量评估结果

使用以下评价指标评估融合结果质量：

| 指标 | 全称                    | 含义       |
| ---- | ----------------------- | ---------- |
| MI   | Mutual Information      | 互信息     |
| SSIM | Structural Similarity   | 结构相似性 |
| CC   | Correlation Coefficient | 相关系数   |
| EN   | Entropy                 | 信息熵     |
| SF   | Spatial Frequency       | 空间频率   |
| AG   | Average Gradient        | 平均梯度   |
| SD   | Standard Deviation      | 标准差     |

**融合结果评估**:

| 模态        |   MI   |  SSIM  |   CC   |   EN   |   SF    |    AG    |   SD    |
| ----------- | :----: | :----: | :----: | :----: | :-----: | :------: | :-----: |
| **RGB-IR**  | 1.3452 | 0.6929 | 0.4176 | 6.8392 | 10.2869 | 40.0253  | 32.1009 |
| **PET-MRI** | 1.2601 | 0.3122 | 0.8322 | 5.0029 | 43.4577 | 119.1321 | 76.9609 |
| **CT-MRI**  | 1.3694 | 0.6769 | 0.7901 | 5.2487 | 44.1857 | 118.6856 | 75.8238 |

### 5.3 定性评估

#### RGB-IR 融合结果

- 成功保留了可见光图像的纹理细节
- 有效融合了红外图像的热目标信息
- 边缘清晰，对比度适中

#### 医学图像融合结果 (PET-MRI, CT-MRI)

- 解剖结构清晰 (来自 MRI/CT)
- 功能信息完整 (来自 PET)
- 融合图像自然，无明显伪影

### 5.4 配准精度

RGB-IR Task 2 输出的仿射变换矩阵：

```
[[ 1.0302006  -0.03416662 -0.002363  ]
 [ 0.08091667  1.0669252  -0.00170587]]
```

解读：
- 缩放因子: ~1.03-1.07 (轻微缩放)
- 旋转角度: ~2-5° (轻微旋转)
- 平移量: 很小 (图像基本对齐)

---

## 6. 创新点与优势

### 6.1 技术创新

#### 创新点一: 互增强机制

传统方法将配准和融合作为独立任务，MURF 首次提出：
- 融合结果可以反馈指导配准
- 配准精度提升可以改善融合质量
- 形成正向循环，整体性能优于独立优化

#### 创新点二: 共享信息提取

- 通过对比学习提取跨模态共享描述符
- 有效弥合不同模态间的外观差异
- 为后续配准提供可靠的匹配基础

#### 创新点三: 多尺度粗到精策略

- 金字塔结构从粗到精逐步优化
- 先处理大位移，再处理细节对齐
- 提高配准鲁棒性和精度

#### 创新点四: 可变形融合网络

- 使用可变形卷积处理局部几何失配
- 通道注意力机制自适应加权不同模态特征
- 端到端学习，无需手工设计融合规则

### 6.2 方法优势

| 特性             | MURF  | 传统方法 |
| ---------------- | :---: | :------: |
| 端到端学习       |   ✅   |    ❌     |
| 配准融合联合优化 |   ✅   |    ❌     |
| 跨模态特征学习   |   ✅   |    ❌     |
| 多尺度处理       |   ✅   |   部分   |
| 无需手工特征     |   ✅   |    ❌     |

### 6.3 性能优势

相比其他方法，MURF 在多个数据集上取得 SOTA 性能：

- **配准精度**: 关键点匹配误差降低 20-30%
- **融合质量**: MI、SSIM 等指标提升 5-15%
- **运行效率**: 端到端推理，无需迭代优化

---

## 7. 应用场景

### 7.1 安防监控

**场景**: 全天候目标检测与跟踪

- 白天使用可见光图像获取丰富纹理
- 夜间使用红外图像检测热目标
- MURF 融合提供 24 小时可靠监控

```
可见光 (白天)  +  红外 (夜间)  →  全天候融合图像
     ↓                ↓                  ↓
 纹理细节          热目标           目标+场景
```

### 7.2 自动驾驶

**场景**: 恶劣天气下的环境感知

- 雾天/雨天可见光成像质量下降
- 红外不受天气影响，可穿透烟雾
- 融合图像提升恶劣条件下的感知能力

### 7.3 医学诊断

**场景**: 肿瘤定位与诊断

```
PET (功能成像)     +    MRI (解剖成像)
     ↓                       ↓
 肿瘤代谢活性            组织结构
     ↓                       ↓
     └───────── MURF 融合 ─────────┘
                   ↓
          精确定位 + 全面信息
```

**优势**:
- PET 提供肿瘤代谢信息 (功能)
- MRI 提供软组织结构 (解剖)
- 融合图像帮助医生精确定位病灶

### 7.4 遥感监测

**场景**: 农业、环境监测

- 可见光反映植被颜色
- 近红外反映叶绿素含量
- 融合图像评估植被健康状况

### 7.5 军事应用

**场景**: 目标识别与战场感知

- 融合多源传感器信息
- 提升复杂环境下的态势感知能力
- 增强伪装目标检测能力

---

## 8. 总结与展望

### 8.1 复现总结

本项目成功复现了 MURF 论文的核心功能：

**完成情况**:
- ✅ 4 个模态的 Task 1 (共享信息提取)
- ✅ 4 个模态的 Task 2 (多尺度粗配准)
- ✅ 3 个模态的 Task 3 (精细配准与融合)
- ❌ RGB-NIR Task 3 (无预训练模型)

**技术贡献**:
- 完成 TensorFlow 1.x → 2.x 的代码迁移
- 解决多个兼容性问题
- 提供完整的复现指南和测试脚本

### 8.2 局限性

1. **数据集规模有限**: 测试仅使用少量图像，未进行大规模验证
2. **缺少训练验证**: 仅使用预训练模型，未从头训练验证
3. **定量对比不足**: 未与其他方法进行详细对比实验

### 8.3 未来展望

#### 短期改进

- 收集更多测试数据进行全面评估
- 尝试从头训练，验证训练流程
- 与其他 SOTA 方法进行对比实验

#### 长期方向

- **模型轻量化**: 压缩模型用于边缘设备部署
- **实时处理**: 优化推理速度满足实时应用需求
- **更多模态**: 扩展到雷达、激光雷达等更多传感器

---

## 9. 参考文献

```bibtex
@article{xu2023murf,
  title={MURF: Mutually Reinforcing Multi-modal Image Registration and Fusion},
  author={Xu, Han and Ma, Jiayi and Yuan, Jiteng and Le, Zhuliang and Liu, Wei},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={45},
  number={10},
  pages={12148--12166},
  year={2023},
  publisher={IEEE}
}

@inproceedings{xu2022rfnet,
  title={RFNet: Unsupervised Network for Mutually Reinforcing Multi-modal Image Registration and Fusion},
  author={Xu, Han and Ma, Jiayi and Yuan, Jiteng and Le, Zhuliang and Liu, Wei},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={19679--19688},
  year={2022}
}

@article{ma2019infrared,
  title={Infrared and visible image fusion methods and applications: A survey},
  author={Ma, Jiayi and Ma, Yong and Li, Chang},
  journal={Information Fusion},
  volume={45},
  pages={153--178},
  year={2019},
  publisher={Elsevier}
}
```

---

## 附录

### A. 文件结构

```
MURF/
├── README.md                    # 官方说明
├── TPAMI_MURF.pdf              # 论文 PDF
├── REPRODUCTION_GUIDE.md        # 复现指南
├── EXPERIMENT_LOG.md            # 实验日志
├── PROJECT_REPORT.md            # 本报告
├── setup_env.sh                 # 环境配置脚本
├── activate_gpu.sh              # GPU 激活脚本
├── run_all_tests.sh             # 测试脚本
├── evaluate_results.py          # 评估脚本
├── RGB-IR/                      # RGB-红外模块
├── RGB-NIR/                     # RGB-近红外模块
├── PET-MRI/                     # PET-MRI 模块
└── CT-MRI/                      # CT-MRI 模块
```

### B. 快速使用

```bash
# 1. 配置环境
cd /home/sh/MURF
bash setup_env.sh

# 2. 激活环境
source activate_gpu.sh

# 3. 运行测试
bash run_all_tests.sh

# 4. 评估结果
python evaluate_results.py
```

---

**报告完成时间**: 2025年12月27日
